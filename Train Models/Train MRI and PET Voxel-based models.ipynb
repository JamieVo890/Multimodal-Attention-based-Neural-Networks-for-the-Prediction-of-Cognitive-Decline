{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10d88a6",
   "metadata": {},
   "source": [
    "# Voxel Based Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e157b61",
   "metadata": {},
   "source": [
    "As a part of the ablation study, we train 4 voxel base models to compare their performances against the patch-based architectures:\n",
    "- A voxel-based model trained on MRI scans\n",
    "- A voxel-based model trained on PET scans\n",
    "- A voxel-based multimodal model trained on the combined feature maps of the MRI and PET models\n",
    "- A voxel-based multimodal model trained on the combined feature maps of the MRI and PET models using attention\n",
    "\n",
    "3D ResNet architecture code is adapted from https://github.com/kenshohara/3D-ResNets-PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbc8cd",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00559bb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "import nibabel as nb\n",
    "import torchio as tio\n",
    "\n",
    "from models import ResNetV2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9473e0",
   "metadata": {},
   "source": [
    "## Read in MRI and PET images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dcdafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject IDs who are progressive normal cognition (will develop MCI or AD within 10 years)\n",
    "PNC = pd.read_pickle('PNC.pkl')\n",
    "\n",
    "# Subject IDs who are stable normal cognition (will remain CN within 10 years)\n",
    "SNC = pd.read_pickle('SNC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "017ee272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "\n",
    "def read_image_data(input_path):\n",
    "\"\"\"Reads in MRI and PET image data from specified directory, along with corresponding subject ids.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_path : str\n",
    "        The input directory of the image data and subject ids\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_train : np.array\n",
    "        a numpy array containing image data\n",
    "        \n",
    "    y_train : np.array\n",
    "        a numpy array containing labels for image data\n",
    "        \n",
    "    ids : np.array\n",
    "        a numpy array containing subject ids of image data\n",
    "\"\"\"\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    ids = []\n",
    "    for filename in sorted(os.listdir(input_path)):\n",
    "        file = os.path.join(input_path, filename)\n",
    "        img_file = nb.load(file)\n",
    "        img = img_file.get_fdata()\n",
    "        X_train.append(img)\n",
    "        ids.append(filename)\n",
    "        \n",
    "        # Progressive normal cognition target class 1\n",
    "        if filename[0:8] in np.array(PNC):\n",
    "            y_train.append(1)\n",
    "        # Stable normal cognition class 0\n",
    "        else:\n",
    "            y_train.append(0)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    # Reshape X_train to include channel dimension\n",
    "    X_train = X_train.reshape(X_train.shape + (1,))\n",
    "    return X_train, y_train, ids\n",
    "\n",
    "\n",
    "X_train_MRI, y_train_MRI, ids_MRI = read_image_data(\"E:/Work/Processed_MRI/2.MNI_Registration\")\n",
    "X_train_PET, y_train_PET, ids_PET = read_image_data(\"E:/Work/Processed_PIB/4.MNI_Registered\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6283bef",
   "metadata": {},
   "source": [
    "## Creating training and test sets for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a32aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.6 - 0.2 - 0.2 train-val-test split\n",
    "X_train_MRI, X_test_MRI, X_train_PET, X_test_PET, ids_train, ids_test, y_train, y_test = train_test_split(X_train_MRI, \n",
    "                                                                                     X_train_PET, ids_MRI, \n",
    "                                                                                     y_train_MRI, test_size=0.2, \n",
    "                                                                                     random_state=101, stratify=y_train_MRI)\n",
    "\n",
    "X_train_MRI, X_val_MRI, X_train_PET, X_val_PET, ids_train, ids_val, y_train, y_val = train_test_split(X_train_MRI, X_train_PET, \n",
    "                                                                                      ids_train, y_train, \n",
    "                                                                                      test_size=0.25, random_state=101,\n",
    "                                                                                      stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0176a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datasets to tensor format, with channel first\n",
    "train_x_MRI = torch.from_numpy(X_train_MRI).float().permute(0,4,1,2,3)\n",
    "train_x_PET = torch.from_numpy(X_train_PET).float().permute(0,4,1,2,3)\n",
    "train_y = torch.from_numpy(y_train).float()\n",
    "\n",
    "val_x_MRI = torch.from_numpy(X_val_MRI).float().permute(0,4,1,2,3)\n",
    "val_x_PET = torch.from_numpy(X_val_PET).float().permute(0,4,1,2,3)\n",
    "val_y = torch.from_numpy(y_val).float()\n",
    "\n",
    "test_x_MRI = torch.from_numpy(X_test_MRI).float().permute(0,4,1,2,3)\n",
    "test_x_PET = torch.from_numpy(X_test_PET).float().permute(0,4,1,2,3)\n",
    "test_y = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb06a24",
   "metadata": {},
   "source": [
    "## Perform data augmentation to increase training set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c63c15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def perform_augmentation(dataset, seed):\n",
    "\"\"\"\n",
    "    Performs augmentation to image data. To simulate different positions and size of the patient \n",
    "    within the scanner, and anatomical variations present in the images, random affine transformations, \n",
    "    elastic deformations and flips are applied to the images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : torch.tensor\n",
    "        Pytorch tensor of image data being augmented\n",
    "        \n",
    "    seed : int\n",
    "        Seed for random number generation\n",
    "\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Define transformations\n",
    "    training_transform = tio.Compose([\n",
    "        tio.RandomAffine(),\n",
    "        tio.RandomElasticDeformation(),\n",
    "        tio.RandomFlip()\n",
    "    ])\n",
    "    augmented_dataset = torch.clone(dataset) \n",
    "    for i in range(len(augmented_dataset)):\n",
    "        augmented_dataset[i] = training_transform(augmented_dataset[i])\n",
    "    return augmented_dataset\n",
    "\n",
    "\n",
    "orig_train_x_MRI = torch.clone(train_x_MRI)\n",
    "orig_train_x_PET = torch.clone(train_x_PET)\n",
    "orig_train_y = torch.clone(train_y)\n",
    "\n",
    "for seed in [1,101,42]:\n",
    "    # Apply transformations and create augmented training set\n",
    "    augmented_train_MRI = perform_augmentation(orig_train_x_MRI, seed)\n",
    "    augmented_train_PET = perform_augmentation(orig_train_x_PET, seed)\n",
    "    \n",
    "    \n",
    "    # Concatenate training and augmented training datasets\n",
    "    train_x_MRI = torch.cat((train_x_MRI, augmented_train_MRI), 0)\n",
    "    train_x_PET = torch.cat((train_x_PET, augmented_train_PET), 0)\n",
    "    train_y = torch.cat((train_y, orig_train_y), 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb42e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preaugmented data (for reruns)\n",
    "train_x_MRI = torch.load(\"train_x_MRI.pkl\")\n",
    "train_x_PET = torch.load(\"train_x_PET.pkl\")\n",
    "train_y = torch.load(\"train_y.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3509d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pytorch train and test sets\n",
    "train_MRI = torch.utils.data.TensorDataset(train_x_MRI,train_y)\n",
    "train_PET = torch.utils.data.TensorDataset(train_x_PET,train_y)\n",
    "\n",
    "val_MRI = torch.utils.data.TensorDataset(val_x_MRI,val_y)\n",
    "val_PET = torch.utils.data.TensorDataset(val_x_PET,val_y)\n",
    "\n",
    "test_MRI = torch.utils.data.TensorDataset(test_x_MRI,test_y)\n",
    "test_PET = torch.utils.data.TensorDataset(test_x_PET,test_y)\n",
    "\n",
    "\n",
    "# Create data loader\n",
    "batch_size = 16\n",
    "train_loader_MRI = torch.utils.data.DataLoader(train_MRI, batch_size = batch_size, shuffle = True)\n",
    "train_loader_PET = torch.utils.data.DataLoader(train_PET, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "val_loader_MRI = torch.utils.data.DataLoader(val_MRI, batch_size = batch_size, shuffle = False)\n",
    "val_loader_PET= torch.utils.data.DataLoader(val_PET, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "test_loader_MRI = torch.utils.data.DataLoader(test_MRI, batch_size = batch_size, shuffle = False)\n",
    "test_loader_PET = torch.utils.data.DataLoader(test_PET, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d14be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device being used for model training\n",
    "if torch.cuda.is_available(): \n",
    "    dev = \"cuda:0\" \n",
    "else: \n",
    "    dev = \"cpu\" \n",
    "device = torch.device(dev) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734fb57",
   "metadata": {},
   "source": [
    "# Train  Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8406fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimiser, error, scheduler, feature_map = False):\n",
    "\"\"\"\n",
    "    Trains model and performs gradient updates using training data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The pytorch model to be trained\n",
    "\n",
    "    train_loader : torch.utils.data.DataLoader\n",
    "        Dataloader used for training set\n",
    "        \n",
    "    optimiser : torch.optim optimisers for pytorch e.g torch.optim.SGD\n",
    "        Optimiser used for model training\n",
    "        \n",
    "    error : torch.nn loss functions for pytorch e.g nn.BCELoss\n",
    "        Loss function used for model training\n",
    "        \n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Scheduler used to adjust learning rate during training\n",
    "        \n",
    "    feature_map : Boolean\n",
    "        Flag indicating whether the input model returns both the final layer output\n",
    "        and previous feature maps\n",
    "\"\"\"\n",
    "    total_train_loss = 0\n",
    "    for image, labels in train_loader:\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        # feature_map indicates whether the feature map prior final layer is also included in the outputs of the model\n",
    "        if feature_map:\n",
    "            outputs = model(image)[1]\n",
    "        else:\n",
    "            outputs = model(image)\n",
    "            \n",
    "        # Calculate loss\n",
    "        loss = error(outputs.flatten(), labels)\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Clear GPU Cache\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = outputs.flatten().round()\n",
    "    #print(\"Average Training Loss\", total_train_loss/len(train_loader.dataset))\n",
    "    \n",
    "    \n",
    "def validate_model(model, val_loader, error, feature_map = False):\n",
    "\"\"\"\n",
    "    Tests validation set on input model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The pytorch model to be trained\n",
    "\n",
    "    val_loader : torch.utils.data.DataLoader\n",
    "        Dataloader used for validation set\n",
    "        \n",
    "    error : torch.nn loss functions for pytorch e.g nn.BCELoss\n",
    "        Loss function used for model training\n",
    "        \n",
    "    feature_map : Boolean\n",
    "        Flag indicating whether the input model returns both the final layer output\n",
    "        and previous feature maps\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    validation_loss : float\n",
    "        validation loss of model\n",
    "\"\"\"\n",
    "    correct_predictions_val = 0\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for image, labels in val_loader:\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            if feature_map:\n",
    "                pred = model(image)[1]\n",
    "            else:\n",
    "                pred = model(image)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = error(pred.flatten(), labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # Clear GPU Cache\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            preds = pred.flatten().round()\n",
    "            correct_predictions_val += torch.sum(preds == labels).item()\n",
    "        #print(\"Validation Accuracy:\", correct_predictions_val/len(val_loader.dataset))\n",
    "        #print(\"Average Validation Loss:\", total_val_loss/len(val_loader.dataset))\n",
    "    validation_loss = total_val_loss/len(val_loader.dataset)\n",
    "    return validation_loss\n",
    "        \n",
    "def evaluate_model(model, test_loader, error, feature_map = False):\n",
    "\"\"\"\n",
    "    Evaluates input model on test set. Prints out the model's accuracy, true positive rate,\n",
    "    true negative rate, and predictions against the true labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The pytorch model to be trained\n",
    "\n",
    "    test_loader : torch.utils.data.DataLoader\n",
    "        Dataloader used for test set\n",
    "        \n",
    "    error : torch.nn loss functions for pytorch e.g nn.BCELoss\n",
    "        Loss function used for model training\n",
    "        \n",
    "    feature_map : Boolean\n",
    "        Flag indicating whether the input model returns both the final layer output\n",
    "        and previous feature maps\n",
    "\"\"\"\n",
    "    correct_predictions_test = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for test,label in test_loader:\n",
    "            test = test.to(device)\n",
    "            label = label.to(device)\n",
    "            labels.append(label.cpu())\n",
    "            \n",
    "            # Forward propagation\n",
    "            if feature_map:\n",
    "                pred = model(test)[1]\n",
    "            else:\n",
    "                pred = model(test)\n",
    "\n",
    "            # Clear GPU Cache\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            pred = pred.flatten().round()\n",
    "            preds.append(pred.cpu())\n",
    "            correct_predictions_test += torch.sum(pred == label).item()\n",
    "    print(\"Test Accuracy:\", correct_predictions_test/len(test_loader.dataset))    \n",
    "    print(\"True Positive Rate:\", recall_score(torch.cat(labels), torch.cat(preds)))\n",
    "    print(\"True Negative Rate:\", specificity_score(torch.cat(labels), torch.cat(preds)))\n",
    "    print(\"Predictions:\",preds)\n",
    "    print(\"True Labels:\",labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7cd69b",
   "metadata": {},
   "source": [
    "### MRI Voxel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "777af4f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST VAL LOSS: 0.04955683975684934\n",
      "----------------------------TEST RESULTS-------------------------------\n",
      "Test Accuracy: 0.6097560975609756\n",
      "True Positive Rate: 0.7619047619047619\n",
      "True Negative Rate: 0.45\n",
      "Predictions: [tensor([1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.]), tensor([0., 1., 0., 1., 1., 1., 0., 1., 0.])]\n",
      "True Labels: [tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.]), tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.]), tensor([0., 0., 0., 1., 1., 1., 1., 1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "#Instantiate ResNet Model\n",
    "resnet = ResNetV2.generate_model(\n",
    "        model_depth=10,\n",
    "        n_classes=1,\n",
    "        n_input_channels=1,\n",
    "        shortcut_type='B',\n",
    "        conv1_t_size=7,\n",
    "        conv1_t_stride=2,\n",
    "        no_max_pool=False,\n",
    "        widen_factor=1.0)\n",
    "MRI_model = resnet.to(device)\n",
    "\n",
    "\n",
    "# Set Seeds for deterministic results\n",
    "torch.manual_seed(101)\n",
    "torch.cuda.manual_seed(101)\n",
    "random.seed(101)\n",
    "np.random.seed(101)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed_all(101)\n",
    "\n",
    "# Binary Cross Entropy Loss\n",
    "error = nn.BCELoss()\n",
    "\n",
    "# Define optimiser\n",
    "optimiser = SGD(MRI_model.parameters(), lr=0.001,momentum=0.9)\n",
    "scheduler = lr_scheduler.LinearLR(optimiser, start_factor=1.0, end_factor=0.1, total_iters=10)\n",
    "\n",
    "# Validation hyperparamters for early stopping\n",
    "best_val_loss = np.inf\n",
    "patience = 20\n",
    "no_improvement = 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    #print(f\"----------------------------EPOCH {epoch}-------------------------------\")\n",
    "    MRI_model.train()\n",
    "    train_model(MRI_model, train_loader_MRI, optimiser, error, scheduler, True)\n",
    "    \n",
    "    MRI_model.eval()\n",
    "    val_loss = validate_model(MRI_model, val_loader_MRI, error, True)\n",
    "    \n",
    "    # Save model weights if improvement seen\n",
    "    # Otherwise stop model training if there is no improvement in loss after \"patience\" number of runs\n",
    "    if val_loss <= best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement = 0\n",
    "        torch.save(MRI_model.state_dict(), \"./trained_models/MRI\")\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "        if no_improvement <= patience:\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"BEST VAL LOSS: {best_val_loss}\")\n",
    "            break\n",
    "            \n",
    "print(\"----------------------------TEST RESULTS-------------------------------\")\n",
    "MRI_model.load_state_dict(torch.load(\"./trained_models/MRI\"))\n",
    "MRI_model.eval()\n",
    "evaluate_model(MRI_model, test_loader_MRI, error, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4648092",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OAS30314_MR_d.nii.gz\n",
      "OAS30895_MR_d.nii.gz\n",
      "OAS30830_MR_d.nii.gz\n",
      "OAS31059_MR_d.nii.gz\n",
      "OAS30079_MR_d.nii.gz\n",
      "OAS30986_MR_d.nii.gz\n",
      "OAS30929_MR_d.nii.gz\n",
      "OAS30241_MR_d.nii.gz\n",
      "OAS30032_MR_d.nii.gz\n",
      "OAS30224_MR_d.nii.gz\n",
      "OAS30921_MR_d.nii.gz\n",
      "OAS30614_MR_d.nii.gz\n",
      "OAS31092_MR_d.nii.gz\n",
      "OAS31162_MR_d.nii.gz\n",
      "OAS30041_MR_d.nii.gz\n",
      "OAS31168_MR_d.nii.gz\n",
      "OAS30028_MR_d.nii.gz\n",
      "OAS30015_MR_d.nii.gz\n",
      "OAS30735_MR_d.nii.gz\n",
      "OAS31103_MR_d.nii.gz\n",
      "OAS30749_MR_d.nii.gz\n",
      "OAS30991_MR_d.nii.gz\n",
      "OAS30223_MR_d.nii.gz\n",
      "OAS30572_MR_d.nii.gz\n",
      "OAS31087_MR_d.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Print which subjects were correctly classified by the MRI model\n",
    "predictions = [torch.tensor([1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.]),\n",
    "     torch.tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.]),\n",
    "     torch.tensor([0., 1., 0., 1., 1., 1., 0., 1., 0.])]\n",
    "\n",
    "\n",
    "labels = [torch.tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.]),\n",
    "               torch.tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.]),\n",
    "               torch.tensor([0., 0., 0., 1., 1., 1., 1., 1., 0.])]\n",
    "labels = torch.cat(labels)\n",
    "predictions = torch.cat(predictions)\n",
    "correct = labels==predictions\n",
    "for i in range(41):\n",
    "    if correct[i]:\n",
    "        print(ids_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc4d94b",
   "metadata": {},
   "source": [
    "### PET Voxel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ceb14af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST VAL LOSS: 0.04739496039181221\n",
      "----------------------------TEST RESULTS-------------------------------\n",
      "Test Accuracy: 0.7073170731707317\n",
      "True Positive Rate: 0.6666666666666666\n",
      "True Negative Rate: 0.75\n",
      "Predictions: [tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.]), tensor([0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.]), tensor([0., 0., 0., 0., 1., 1., 1., 1., 1.])]\n",
      "True Labels: [tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.]), tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.]), tensor([0., 0., 0., 1., 1., 1., 1., 1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "#Instantiate ResNet Model\n",
    "resnet = ResNetV2.generate_model(\n",
    "        model_depth=10,\n",
    "        n_classes=1,\n",
    "        n_input_channels=1,\n",
    "        shortcut_type='B',\n",
    "        conv1_t_size=7,\n",
    "        conv1_t_stride=2,\n",
    "        no_max_pool=False,\n",
    "        widen_factor=1.0)\n",
    "\n",
    "PET_model = resnet.to(device)\n",
    "\n",
    "# Set Seeds for deterministic results\n",
    "torch.manual_seed(101)\n",
    "torch.cuda.manual_seed(101)\n",
    "random.seed(101)\n",
    "np.random.seed(101)\n",
    "\n",
    "# Binary Cross Entropy Loss\n",
    "error = nn.BCELoss()\n",
    "\n",
    "# Define optimiser\n",
    "optimiser = SGD(PET_model.parameters(), lr=0.001,momentum=0.9)\n",
    "scheduler = lr_scheduler.LinearLR(optimiser, start_factor=1.0, end_factor=0.1, total_iters=10)\n",
    "\n",
    "# Validation hyperparamters for early stopping\n",
    "best_val_loss = np.inf\n",
    "patience = 20\n",
    "no_improvement = 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    #print(f\"----------------------------EPOCH {epoch}-------------------------------\")\n",
    "    PET_model.train()\n",
    "    train_model(PET_model, train_loader_PET, optimiser, error, scheduler, True)\n",
    "    \n",
    "    PET_model.eval()\n",
    "    avg_val_loss = validate_model(PET_model, val_loader_PET, error, True)\n",
    "    \n",
    "    # Save model weights if improvement seen\n",
    "    # Otherwise stop model training if there is no improvement in loss after \"patience\" number of runs\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        no_improvement = 0\n",
    "        torch.save(PET_model.state_dict(), \"./trained_models/PET\")\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "        if no_improvement <= patience:\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"BEST VAL LOSS: {best_val_loss}\")\n",
    "            break\n",
    "            \n",
    "print(\"----------------------------TEST RESULTS-------------------------------\")\n",
    "PET_model.load_state_dict(torch.load(\"./trained_models/PET\"))\n",
    "PET_model.eval()\n",
    "evaluate_model(PET_model, test_loader_PET, error, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cd05798",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OAS30314_MR_d.nii.gz\n",
      "OAS30146_MR_d.nii.gz\n",
      "OAS30895_MR_d.nii.gz\n",
      "OAS30830_MR_d.nii.gz\n",
      "OAS31059_MR_d.nii.gz\n",
      "OAS30079_MR_d.nii.gz\n",
      "OAS30986_MR_d.nii.gz\n",
      "OAS30929_MR_d.nii.gz\n",
      "OAS31125_MR_d.nii.gz\n",
      "OAS30032_MR_d.nii.gz\n",
      "OAS30224_MR_d.nii.gz\n",
      "OAS30823_MR_d.nii.gz\n",
      "OAS30907_MR_d.nii.gz\n",
      "OAS30921_MR_d.nii.gz\n",
      "OAS31162_MR_d.nii.gz\n",
      "OAS31344_MR_d.nii.gz\n",
      "OAS30101_MR_d.nii.gz\n",
      "OAS30769_MR_d.nii.gz\n",
      "OAS30933_MR_d.nii.gz\n",
      "OAS30959_MR_d.nii.gz\n",
      "OAS30028_MR_d.nii.gz\n",
      "OAS30015_MR_d.nii.gz\n",
      "OAS30735_MR_d.nii.gz\n",
      "OAS30160_MR_d.nii.gz\n",
      "OAS31103_MR_d.nii.gz\n",
      "OAS30991_MR_d.nii.gz\n",
      "OAS30223_MR_d.nii.gz\n",
      "OAS30964_MR_d.nii.gz\n",
      "OAS30572_MR_d.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Print which subjects were correctly classified by the PET model\n",
    "predictions = [torch.tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.]),\n",
    "     torch.tensor([0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.]),\n",
    "     torch.tensor([0., 0., 0., 0., 1., 1., 1., 1., 1.])]\n",
    "\n",
    "\n",
    "labels = [torch.tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.]),\n",
    "               torch.tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.]),\n",
    "               torch.tensor([0., 0., 0., 1., 1., 1., 1., 1., 0.])]\n",
    "labels = torch.cat(labels)\n",
    "predictions = torch.cat(predictions)\n",
    "correct = labels==predictions\n",
    "for i in range(41):\n",
    "    if correct[i]:\n",
    "        print(ids_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7297af03",
   "metadata": {},
   "source": [
    "### Multimodal PET+MRI models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f817bffa",
   "metadata": {},
   "source": [
    "The models below combine the feature maps of the pretrained MRI and PET models for classification. We train two variants, one using attention mechanisms, and one using no attention mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42f173a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload train MRI and PET model weights(for rerunning)\n",
    "models = []\n",
    "pet_model = ResNetV2.generate_model(\n",
    "    model_depth=10,\n",
    "    n_classes=1,\n",
    "    n_input_channels=1,\n",
    "    shortcut_type='B',\n",
    "    conv1_t_size=7,\n",
    "    conv1_t_stride=2,\n",
    "    no_max_pool=False,\n",
    "    widen_factor=1.0).to(device)\n",
    "pet_model.load_state_dict(torch.load(f\"./trained_models/PET\"))\n",
    "\n",
    "mri_model = ResNetV2.generate_model(\n",
    "    model_depth=10,\n",
    "    n_classes=1,\n",
    "    n_input_channels=1,\n",
    "    shortcut_type='B',\n",
    "    conv1_t_size=7,\n",
    "    conv1_t_stride=2,\n",
    "    no_max_pool=False,\n",
    "    widen_factor=1.0).to(device)\n",
    "mri_model.load_state_dict(torch.load(f\"./trained_models/MRI\"))\n",
    "\n",
    "models.append(pet_model)\n",
    "models.append(mri_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb373f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multimodal_CNN(nn.Module):\n",
    "\"\"\"\n",
    "    This model uses the feature maps of the individual PET and MRI models as inputs.\n",
    "    Feature maps of both MRI and PET models are concatenated and passed through\n",
    "    a dense layer.\n",
    "\"\"\"\n",
    "    def __init__(self, image_models):\n",
    "        super().__init__()\n",
    "        self.image_models = nn.ModuleList(image_models)\n",
    "        self.drop= nn.Dropout(p=0.4)\n",
    "        self.fc3 = nn.Linear(200, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        image_outputs = []\n",
    "        for i in range(2):\n",
    "            image_output = self.image_models[i](x[i])[0]  \n",
    "            image_outputs.append(self.drop(image_output))\n",
    "        x = torch.cat(image_outputs, dim=1)\n",
    "      \n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfd5c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multimodal attention network\n",
    "# This model passes the feature maps of the individual PET and MRI models through a multihead-attention layer \n",
    "# to create shared representations of the features\n",
    "class multimodal_attention_CNN(nn.Module):\n",
    "\"\"\"\n",
    "    This model uses the feature maps of the individual PET and MRI models as inputs.\n",
    "    Feature maps of both MRI and PET models are concatenated and passed through\n",
    "    a multiheaded-attention layer to create shared representations\n",
    "    of the features. Attention-weighted features of the MRI and PETare then flattened\n",
    "    and passed thorugh a dense layer.\n",
    "\"\"\"\n",
    "    def __init__(self, image_models):\n",
    "        super().__init__()\n",
    "        self.image_models = nn.ModuleList(image_models)\n",
    "        self.drop= nn.Dropout(p=0.4)\n",
    "        self.att = nn.MultiheadAttention(embed_dim=100, num_heads=4, dropout=0.4)\n",
    "        self.fc3 = nn.Linear(200, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        image_outputs = []\n",
    "        for i in range(2):\n",
    "            image_output = self.image_models[i](x[i])[0]  \n",
    "            image_outputs.append(self.drop(image_output))\n",
    "        x = torch.stack(image_outputs)\n",
    "        x, _ = self.att(x,x,x)\n",
    "        \n",
    "        x = x.permute(1,0,2)\n",
    "        x = x.reshape(x.shape[0],200)\n",
    "      \n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a8a1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pytorch train and test sets containing both MRI and PET\n",
    "train_MRI_PET = torch.utils.data.TensorDataset(train_x_MRI,train_x_PET,train_y)\n",
    "val_MRI_PET = torch.utils.data.TensorDataset(val_x_MRI,val_x_PET,val_y)\n",
    "test_MRI_PET = torch.utils.data.TensorDataset(test_x_MRI,test_x_PET,test_y)\n",
    "\n",
    "\n",
    "# Create data loader\n",
    "batch_size = 16\n",
    "train_loader_MRI_PET = torch.utils.data.DataLoader(train_MRI_PET, batch_size = batch_size, shuffle = True)\n",
    "val_loader_MRI_PET = torch.utils.data.DataLoader(val_MRI_PET, batch_size = batch_size, shuffle = False)\n",
    "test_loader_MRI_PET = torch.utils.data.DataLoader(test_MRI_PET, batch_size = batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf6c14e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multimodal_model(model, train_loader, optimiser, error, scheduler, feature_maps=False):\n",
    "\"\"\"\n",
    "    Trains model and performs gradient updates using multimodal training data. Uses both MRI and PET images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The pytorch model to be trained\n",
    "\n",
    "    train_loader : torch.utils.data.DataLoader\n",
    "        Dataloader used for training set\n",
    "        \n",
    "    optimiser : torch.optim optimisers for pytorch e.g torch.optim.SGD\n",
    "        Optimiser used for model training\n",
    "        \n",
    "    error : torch.nn loss functions for pytorch e.g nn.BCELoss\n",
    "        Loss function used for model training\n",
    "        \n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Scheduler used to adjust learning rate during training\n",
    "        \n",
    "    feature_map : Boolean\n",
    "        Flag indicating whether the input model returns both the final layer output\n",
    "        and previous feature maps\n",
    "\"\"\"\n",
    "    total_train_loss = 0\n",
    "    for MRI_image, PET_image, labels in train_loader:\n",
    "        MRI_image = MRI_image.to(device)\n",
    "        PET_image = PET_image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Clear gradients\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        if feature_maps:\n",
    "            outputs = model((PET_image, MRI_image))[1]\n",
    "        else:\n",
    "            outputs = model((PET_image, MRI_image))\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = error(outputs.flatten(), labels)\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Clear GPU Cache\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = outputs.flatten().round()\n",
    "    #print(\"Average Training Loss\", total_train_loss/len(train_loader.dataset))\n",
    "\n",
    "def validate_multimodal_model(model, val_loader, error, feature_maps=False):\n",
    "\"\"\"\n",
    "    Tests multimodal validation set on input model. Uses both MRI and PET images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The pytorch model to be trained\n",
    "\n",
    "    val_loader : torch.utils.data.DataLoader\n",
    "        Dataloader used for validation set\n",
    "\n",
    "    error : torch.nn loss functions for pytorch e.g nn.BCELoss\n",
    "        Loss function used for model training\n",
    "\n",
    "    feature_map : Boolean\n",
    "        Flag indicating whether the input model returns both the final layer output\n",
    "        and previous feature maps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    validation_loss : float\n",
    "        validation loss of model\n",
    "\"\"\"\n",
    "    correct_predictions_val = 0\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for MRI_image, PET_image, labels in val_loader:\n",
    "            MRI_image = MRI_image.to(device)\n",
    "            PET_image = PET_image.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            if feature_maps:\n",
    "                pred = model((PET_image, MRI_image))[1]\n",
    "            else:\n",
    "                pred = model((PET_image, MRI_image))\n",
    "            \n",
    "            # Calculate softmax and cross entropy loss\n",
    "            loss = error(pred.flatten(), labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # Clear GPU Cache\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            preds = pred.flatten().round()\n",
    "            #print(pred)\n",
    "            correct_predictions_val += torch.sum(preds == labels).item()\n",
    "        #print(\"Validation Accuracy:\", correct_predictions_val/len(val_loader.dataset))\n",
    "        #print(\"Average Validation Loss:\", total_val_loss/len(val_loader.dataset))\n",
    "    validation_loss = total_val_loss/len(val_loader.dataset)\n",
    "    return validation_loss\n",
    "        \n",
    "def evaluate_multimodal_model(model, test_loader, error, feature_maps=False):\n",
    "\"\"\"\n",
    "    Evaluates input model on test set. Uses both MRI and PET images.\n",
    "    Prints out the model's accuracy, true positive rate,true negative rate, \n",
    "    and predictions against the true labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The pytorch model to be trained\n",
    "\n",
    "    test_loader : torch.utils.data.DataLoader\n",
    "        Dataloader used for test set\n",
    "        \n",
    "    error : torch.nn loss functions for pytorch e.g nn.BCELoss\n",
    "        Loss function used for model training\n",
    "        \n",
    "    feature_map : Boolean\n",
    "        Flag indicating whether the input model returns both the final layer output\n",
    "        and previous feature maps\n",
    "\"\"\"\n",
    "    correct_predictions_test = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for MRI_image, PET_image, label in test_loader:\n",
    "            MRI_image = MRI_image.to(device)\n",
    "            PET_image = PET_image.to(device)\n",
    "            \n",
    "            labels.append(label.cpu())\n",
    "            \n",
    "            # Forward propagation\n",
    "            if feature_maps:\n",
    "                pred = model((PET_image, MRI_image))[1]\n",
    "            else:\n",
    "                pred = model((PET_image, MRI_image))\n",
    "\n",
    "            # Clear GPU Cache\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            pred = pred.flatten().round()\n",
    "            preds.append(pred.cpu())\n",
    "            correct_predictions_test += torch.sum(pred.cpu() == label.cpu()).item()\n",
    "    print(\"Test Accuracy:\", correct_predictions_test/len(test_loader.dataset))    \n",
    "    print(\"True Positive Rate:\", recall_score(torch.cat(labels), torch.cat(preds)))\n",
    "    print(\"True Negative Rate:\", specificity_score(torch.cat(labels), torch.cat(preds)))\n",
    "    print(preds)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c1c2a",
   "metadata": {},
   "source": [
    "<b>Multimodal PET-MRI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcad018d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST VAL LOSS: 0.04548225751737269\n",
      "----------------------------TEST RESULTS-------------------------------\n",
      "Test Accuracy: 0.7317073170731707\n",
      "True Positive Rate: 0.8571428571428571\n",
      "True Negative Rate: 0.6\n",
      "[tensor([1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.]), tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.]), tensor([0., 0., 0., 1., 1., 1., 1., 1., 1.])]\n",
      "[tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.]), tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.]), tensor([0., 0., 0., 1., 1., 1., 1., 1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "multimodal_model = multimodal_CNN(models).to(device)\n",
    "\n",
    "# Freeze layers of PET and MRI models\n",
    "for image_models in multimodal_model.image_models:\n",
    "    for name, param in image_models.named_parameters():\n",
    "        param.requires_grad = False \n",
    "\n",
    "# Set Seeds for deterministic results\n",
    "torch.manual_seed(101)\n",
    "torch.cuda.manual_seed(101)\n",
    "random.seed(101)\n",
    "np.random.seed(101)\n",
    "\n",
    "# Binary Cross Entropy Loss\n",
    "error = nn.BCELoss()\n",
    "\n",
    "# Define optimiser\n",
    "optimiser = SGD(multimodal_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.LinearLR(optimiser, start_factor=1.0, end_factor=0.1, total_iters=10)\n",
    "\n",
    "# Validation hyperparameters for early stopping\n",
    "best_val_loss = np.inf\n",
    "patience = 20\n",
    "no_improvement = 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    #print(f\"----------------------------EPOCH {epoch}-------------------------------\")\n",
    "    multimodal_model.train()\n",
    "    train_multimodal_model(multimodal_model, train_loader_MRI_PET, optimiser, error, scheduler)\n",
    "    \n",
    "    multimodal_model.eval()\n",
    "    avg_val_loss = validate_multimodal_model(multimodal_model, val_loader_MRI_PET, error)\n",
    "    \n",
    "    # Save model weights if improvement seen\n",
    "    # Otherwise stop model training if there is no improvement in loss after \"patience\" number of runs\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        no_improvement = 0\n",
    "        torch.save(multimodal_model.state_dict(), \"./trained_models/MRI_PET_VOXEL\")\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "        if no_improvement <= patience:\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"BEST VAL LOSS: {best_val_loss}\")\n",
    "            break\n",
    "            \n",
    "print(\"----------------------------TEST RESULTS-------------------------------\")\n",
    "multimodal_model.load_state_dict(torch.load(\"./trained_models/MRI_PET_VOXEL\"))\n",
    "multimodal_model.eval()\n",
    "evaluate_mutimodal_model(multimodal_model, test_loader_MRI_PET, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93cb28",
   "metadata": {},
   "source": [
    "<b>Multimodal PET-MRI Attention-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b6a10ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST VAL LOSS: 0.04499637062956647\n",
      "----------------------------TEST RESULTS-------------------------------\n",
      "Test Accuracy: 0.7317073170731707\n",
      "True Positive Rate: 0.8095238095238095\n",
      "True Negative Rate: 0.65\n",
      "[tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.]), tensor([0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.]), tensor([0., 0., 0., 1., 1., 1., 1., 1., 1.])]\n",
      "[tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.]), tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.]), tensor([0., 0., 0., 1., 1., 1., 1., 1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "multimodal_attention_model = multimodal_attention_CNN(models).to(device)\n",
    "\n",
    "# Freeze layers of PET and MRI models\n",
    "for image_models in multimodal_attention_model.image_models:\n",
    "    for name, param in image_models.named_parameters():\n",
    "        param.requires_grad = False \n",
    "\n",
    "# Set Seeds for deterministic results\n",
    "torch.manual_seed(101)\n",
    "torch.cuda.manual_seed(101)\n",
    "random.seed(101)\n",
    "np.random.seed(101)\n",
    "\n",
    "# Binary Cross Entropy Loss\n",
    "error = nn.BCELoss()\n",
    "\n",
    "# Define optimiser\n",
    "optimiser = SGD(multimodal_attention_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.LinearLR(optimiser, start_factor=1.0, end_factor=0.1, total_iters=10)\n",
    "\n",
    "# Validation hyperparameters for early stopping\n",
    "best_val_loss = np.inf\n",
    "patience = 20\n",
    "no_improvement = 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    #print(f\"----------------------------EPOCH {epoch}-------------------------------\")\n",
    "    multimodal_attention_model.train()\n",
    "    train_multimodal_model(multimodal_attention_model, train_loader_MRI_PET, optimiser, error, scheduler)\n",
    "    \n",
    "    multimodal_attention_model.eval()\n",
    "    avg_val_loss = validate_multimodal_model(multimodal_attention_model, val_loader_MRI_PET, error)\n",
    "    \n",
    "    # Save model weights if improvement seen\n",
    "    # Otherwise stop model training if there is no improvement in loss after \"patience\" number of runs\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        no_improvement = 0\n",
    "        torch.save(multimodal_attention_model.state_dict(), \"./trained_models/MRI_PET_VOXEL_ATT\")\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "        if no_improvement <= patience:\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"BEST VAL LOSS: {best_val_loss}\")\n",
    "            break\n",
    "            \n",
    "print(\"----------------------------TEST RESULTS-------------------------------\")\n",
    "multimodal_attention_model.load_state_dict(torch.load(\"./trained_models/MRI_PET_VOXEL_ATT\"))\n",
    "multimodal_attention_model.eval()\n",
    "evaluate_multimodal_model(multimodal_attention_model, test_loader_MRI_PET, error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
