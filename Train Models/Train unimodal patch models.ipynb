{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4693ae",
   "metadata": {},
   "source": [
    "# Unimodal Patch Based networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cfec5d",
   "metadata": {},
   "source": [
    "The following models utilise a patch based ensemble architecture. As a part of the ablation study, we train two unimodal patch based models, one trained on MRI images, and the other on PET images. There are two classifcation stages for the unimodal patch based model: \n",
    "- Patch Feature Extraction: \n",
    "    - MRI and PET scans are divided into 27 uniform patches of size 44x45x44. \n",
    "    - 27 ResNet models are trained on patches from each patch location to extract local features.\n",
    "    - 3D ResNet architecture code was adapted from https://github.com/kenshohara/3D-ResNets-PyTorch\n",
    "- Patch fusion:\n",
    "    - Feature maps of the 27 patch models are concatenated and used as inputs to a final model for global classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbc8cd",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00559bb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.metrics import specificity_score\n",
    " \n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "import nibabel as nb\n",
    "import torchio as tio\n",
    "\n",
    "from models import ResNetV2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9473e0",
   "metadata": {},
   "source": [
    "## Read in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dcdafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject IDs who are progressive normal cognition (will develop MCI or AD within 10 years)\n",
    "PNC = pd.read_pickle('PNC.pkl')\n",
    "\n",
    "# Subject IDs who are stable normal cognition (will remain CN within 10 years)\n",
    "SNC = pd.read_pickle('SNC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "017ee272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "\n",
    "def read_image_data(input_path):\n",
    "    \"\"\"Reads in MRI and PET image data from specified directory, along with corresponding subject ids.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_path : str\n",
    "        The input directory of the image data and subject ids\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_train : np.array\n",
    "        a numpy array containing image data\n",
    "        \n",
    "    y_train : np.array\n",
    "        a numpy array containing labels for image data\n",
    "        \n",
    "    ids : np.array\n",
    "        a numpy array containing subject ids of image data\n",
    "    \"\"\"\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    ids = []\n",
    "    for filename in sorted(os.listdir(input_path)):\n",
    "        file = os.path.join(input_path, filename)\n",
    "        img_file = nb.load(file)\n",
    "        img = img_file.get_fdata()\n",
    "        X_train.append(img)\n",
    "        ids.append(filename)\n",
    "        # Progressive normal cognition target class 1\n",
    "        if filename[0:8] in np.array(PNC):\n",
    "            y_train.append(1)\n",
    "        # Stable normal cognition class 0\n",
    "        else:\n",
    "            y_train.append(0)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    # Reshape X_train to include channel dimension\n",
    "    X_train = X_train.reshape(X_train.shape + (1,))\n",
    "    return X_train, y_train, ids\n",
    "\n",
    "X_MRI, y_MRI, ids_MRI = read_image_data(\"E:/Work/Processed_MRI/2.MNI_Registration\")\n",
    "X_PET, y_PET, ids_PET = read_image_data(\"E:/Work/Processed_PIB/4.MNI_Registered\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6283bef",
   "metadata": {},
   "source": [
    "## Creating training and test sets for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a32aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.6 - 0.2 - 0.2 train-val-test split\n",
    "X_train_MRI, X_test_MRI, X_train_PET, X_test_PET, ids_train, ids_test, y_train, y_test = train_test_split(X_MRI, \n",
    "                                                                                     X_PET, ids_MRI, \n",
    "                                                                                     y_MRI, test_size=0.2, \n",
    "                                                                                     random_state=101, stratify=y_MRI)\n",
    "\n",
    "X_train_MRI, X_val_MRI, X_train_PET, X_val_PET, ids_train, ids_val, y_train, y_val = train_test_split(X_train_MRI, X_train_PET, \n",
    "                                                                                      ids_train, y_train, \n",
    "                                                                                      test_size=0.25, random_state=101,\n",
    "                                                                                      stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0176a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datasets to tensor format, with channel first\n",
    "train_x_MRI = torch.from_numpy(X_train_MRI).float().permute(0,4,1,2,3)\n",
    "train_x_PET = torch.from_numpy(X_train_PET).float().permute(0,4,1,2,3)\n",
    "train_y = torch.from_numpy(y_train).float()\n",
    "\n",
    "val_x_MRI = torch.from_numpy(X_val_MRI).float().permute(0,4,1,2,3)\n",
    "val_x_PET = torch.from_numpy(X_val_PET).float().permute(0,4,1,2,3)\n",
    "val_y = torch.from_numpy(y_val).float()\n",
    "\n",
    "test_x_MRI = torch.from_numpy(X_test_MRI).float().permute(0,4,1,2,3)\n",
    "test_x_PET = torch.from_numpy(X_test_PET).float().permute(0,4,1,2,3)\n",
    "test_y = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb06a24",
   "metadata": {},
   "source": [
    "## Perform data augmentation to increase training set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c63c15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def perform_augmentation(dataset, seed):\n",
    "    \"\"\"\n",
    "    Performs augmentation to image data. To simulate different positions and size of the patient \n",
    "    within the scanner, and anatomical variations present in the images, random affine transformations, \n",
    "    elastic deformations and flips are applied to the images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : torch.tensor\n",
    "        Pytorch tensor of image data being augmented\n",
    "        \n",
    "    seed : int\n",
    "        Seed for random number generation\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Define transformations\n",
    "    training_transform = tio.Compose([\n",
    "        tio.RandomAffine(),\n",
    "        tio.RandomElasticDeformation(),\n",
    "        tio.RandomFlip()\n",
    "    ])\n",
    "    augmented_dataset = torch.clone(dataset) \n",
    "    for i in range(len(augmented_dataset)):\n",
    "        augmented_dataset[i] = training_transform(augmented_dataset[i])\n",
    "    return augmented_dataset\n",
    "\n",
    "orig_train_x_MRI = torch.clone(train_x_MRI)\n",
    "orig_train_x_PET = torch.clone(train_x_PET)\n",
    "orig_train_y = torch.clone(train_y)\n",
    "for seed in [1,101,42]:\n",
    "    # Apply transformations and create augmented training set\n",
    "    augmented_train_MRI = perform_augmentation(orig_train_x_MRI, seed)\n",
    "    augmented_train_PET = perform_augmentation(orig_train_x_PET, seed)\n",
    "    \n",
    "    \n",
    "    # Concatenate training and augmented training datasets\n",
    "    train_x_MRI = torch.cat((train_x_MRI, augmented_train_MRI), 0)\n",
    "    train_x_PET = torch.cat((train_x_PET, augmented_train_PET), 0)\n",
    "    train_y = torch.cat((train_y, orig_train_y), 0)\n",
    "\n",
    "# Removing blank space around brain to make dimensions even so we can divide image into uniform patches\n",
    "train_x_MRI = train_x_MRI[:, :, 0:88, 0:108, 0:88]\n",
    "train_x_PET = train_x_PET[:, :, 0:88, 0:108, 0:88]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d5dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load augmented dataset (for reruns)\n",
    "train_x_MRI = torch.load(\"train_x_MRI.pkl\")\n",
    "train_x_PET = torch.load(\"train_x_PET.pkl\")\n",
    "train_y = torch.load(\"train_y.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303434c",
   "metadata": {},
   "source": [
    "## Divide images into patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f66cbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(images, dim, labels):\n",
    "    \"\"\"\n",
    "    For each sample, divides images into 27 uniform 3x3x3 patches of size 44x54x44 with 50% overlap\n",
    "    Then creates 27 training datasets for each patch location \n",
    "    For example a dataset containing patches of each subject in the top left corner\n",
    "    and a dataset containing patches of each subject in the middle \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images : torch.tensor\n",
    "        Pytorch tensor containing image data\n",
    "        \n",
    "    dim : int\n",
    "        Dimension of the input tensor\n",
    "    \n",
    "    labels : torch.tensor\n",
    "        Pytorch tensor containing image data class labels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    datasets : list\n",
    "        List of TensorDatasets containing patches for each patch location\n",
    "    \"\"\"\n",
    "    # Create datasets for each patch location\n",
    "    datasets = [[] for _ in range(27)]\n",
    "    \n",
    "    # Find the starting locations of each patch\n",
    "    starting_points = []\n",
    "    for height_stride in range(3):\n",
    "        for width_stride in range(3):\n",
    "            for depth_stride in range(3):\n",
    "                    start = (0 + height_stride*dim[1]//4, 0 + width_stride*dim[2]//4, 0 + depth_stride*dim[3]//4)\n",
    "                    starting_points.append(start)\n",
    "\n",
    "    # For each image\n",
    "    for i in range(len(images)):\n",
    "        # Create patch from every starting point\n",
    "        for j in range(len(starting_points)):\n",
    "            start_pt = starting_points[j]\n",
    "            patch = images[i][:, start_pt[0]:start_pt[0] + dim[1]//2, \n",
    "                                      start_pt[1]:start_pt[1] + dim[2]//2, \n",
    "                                      start_pt[2]:start_pt[2] + dim[3]//2]\n",
    "            datasets[j].append(patch)\n",
    "            \n",
    "    # For each patch location, stack patches from every sample samples into a tensor as a Tensor Dataset\n",
    "    for i in range(len(datasets)):\n",
    "        datasets[i] = torch.stack(datasets[i])\n",
    "        datasets[i] = torch.utils.data.TensorDataset(datasets[i],labels)\n",
    "    return datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08aff33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for each patch location\n",
    "\n",
    "dim = train_x_MRI[0].shape\n",
    "patch_train_datasets_MRI = create_patches(train_x_MRI, dim, train_y)\n",
    "patch_train_datasets_PET = create_patches(train_x_PET, dim, train_y)\n",
    "\n",
    "patch_val_datasets_MRI = create_patches(val_x_MRI, dim, val_y)\n",
    "patch_val_datasets_PET = create_patches(val_x_PET, dim, val_y)\n",
    "\n",
    "patch_test_datasets_MRI = create_patches(test_x_MRI, dim, test_y)\n",
    "patch_test_datasets_PET = create_patches(test_x_PET, dim, test_y)\n",
    "\n",
    "\n",
    "# Create data loaders for each patch location dataset\n",
    "patch_train_dataloaders_MRI = []\n",
    "patch_train_dataloaders_PET = []\n",
    "\n",
    "patch_val_dataloaders_MRI = []\n",
    "patch_val_dataloaders_PET = []\n",
    "\n",
    "patch_test_dataloaders_MRI = []\n",
    "patch_test_dataloaders_PET = []\n",
    "\n",
    "batch_size = 16\n",
    "for i in range(27):\n",
    "    patch_train_dataloaders_MRI.append(torch.utils.data.DataLoader(patch_train_datasets_MRI[i], \n",
    "                                                                  batch_size = batch_size, shuffle = True))\n",
    "    patch_train_dataloaders_PET.append(torch.utils.data.DataLoader(patch_train_datasets_PET[i], \n",
    "                                                                  batch_size = batch_size, shuffle = True))\n",
    "    \n",
    "    patch_val_dataloaders_MRI.append(torch.utils.data.DataLoader(patch_val_datasets_MRI[i], \n",
    "                                                                  batch_size = batch_size, shuffle = False))\n",
    "    patch_val_dataloaders_PET.append(torch.utils.data.DataLoader(patch_val_datasets_PET[i], \n",
    "                                                                  batch_size = batch_size, shuffle = False))\n",
    "    \n",
    "    patch_test_dataloaders_MRI.append(torch.utils.data.DataLoader(patch_test_datasets_MRI[i], \n",
    "                                                                  batch_size = batch_size, shuffle = False))\n",
    "    patch_test_dataloaders_PET.append(torch.utils.data.DataLoader(patch_test_datasets_PET[i], \n",
    "                                                                  batch_size = batch_size, shuffle = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d14be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device being used for model training\n",
    "if torch.cuda.is_available(): \n",
    "    dev = \"cuda:0\" \n",
    "else: \n",
    "    dev = \"cpu\" \n",
    "device = torch.device(dev) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734fb57",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35201530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimiser, error, scheduler, feature_map=False):\n",
    "    \"\"\"\n",
    "    Trains model and performs gradient updates using training data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The pytorch model to be trained\n",
    "\n",
    "    train_loader : torch.utils.data.DataLoader\n",
    "        Dataloader used for training set\n",
    "        \n",
    "    optimiser : torch.optim optimisers for pytorch e.g torch.optim.SGD\n",
    "        Optimiser used for model training\n",
    "        \n",
    "    error : torch.nn loss functions for pytorch e.g nn.BCELoss\n",
    "        Loss function used for model training\n",
    "        \n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Scheduler used to adjust learning rate during training\n",
    "        \n",
    "    feature_map : Boolean\n",
    "        Flag indicating whether the input model returns both the final layer output\n",
    "        and previous feature maps\n",
    "    \"\"\"\n",
    "    total_train_loss = 0\n",
    "    for image, labels in train_loader:\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        # feature_map indicates whether the feature map prior final layer is also included in the outputs of the model\n",
    "        if feature_map:\n",
    "            outputs = model(image)[1]\n",
    "        else:\n",
    "            outputs = model(image)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = error(outputs.flatten(), labels)\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Clear GPU Cache\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = outputs.flatten().round()\n",
    "    #print(\"Average Training Loss\", total_train_loss/len(train_loader.dataset))\n",
    "\n",
    "def validate_model(model, val_loader, error, feature_map=False):\n",
    "    \"\"\"\n",
    "    Tests validation set on input model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The pytorch model to be trained\n",
    "\n",
    "    val_loader : torch.utils.data.DataLoader\n",
    "        Dataloader used for validation set\n",
    "        \n",
    "    error : torch.nn loss functions for pytorch e.g nn.BCELoss\n",
    "        Loss function used for model training\n",
    "        \n",
    "    feature_map : Boolean\n",
    "        Flag indicating whether the input model returns both the final layer output\n",
    "        and previous feature maps\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    validation_loss : float\n",
    "        validation loss of model\n",
    "    \"\"\"\n",
    "    correct_predictions_val = 0\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for image, labels in val_loader:\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            if feature_map:\n",
    "                pred = model(image)[1]\n",
    "            else:\n",
    "                pred = model(image)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = error(pred.flatten(), labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # Clear GPU Cache\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            preds = pred.flatten().round()\n",
    "            #print(pred)\n",
    "            correct_predictions_val += torch.sum(preds == labels).item()\n",
    "        #print(\"Validation Accuracy:\", correct_predictions_val/len(val_loader.dataset))\n",
    "        #print(\"Average Validation Loss:\", total_val_loss/len(val_loader.dataset))\n",
    "    validation_loss = total_val_loss/len(val_loader.dataset)\n",
    "    return validation_loss\n",
    "        \n",
    "def evaluate_model(model, test_loader, error, feature_map=False, verbose=1):\n",
    "    \"\"\"\n",
    "    Evaluates input model on test set. Prints out the model's accuracy, true positive rate,\n",
    "    true negative rate, and predictions against the true labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The pytorch model to be trained\n",
    "\n",
    "    test_loader : torch.utils.data.DataLoader\n",
    "        Dataloader used for test set\n",
    "        \n",
    "    error : torch.nn loss functions for pytorch e.g nn.BCELoss\n",
    "        Loss function used for model training\n",
    "        \n",
    "    feature_map : Boolean\n",
    "        Flag indicating whether the input model returns both the final layer output\n",
    "        and previous feature maps\n",
    "        \n",
    "    verbpse : Boolean\n",
    "        Flag indicating whether to print final test scores, or return them instead\n",
    "    \"\"\"\n",
    "    correct_predictions_test = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for test,label in test_loader:\n",
    "            test = test.to(device)\n",
    "            label = label.to(device)\n",
    "            labels.append(label.cpu())\n",
    "            \n",
    "            # Forward propagation\n",
    "            if feature_map:\n",
    "                pred = model(test)[1]\n",
    "            else:\n",
    "                pred = model(test)\n",
    "\n",
    "            # Clear GPU Cache\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            pred = pred.flatten().round()\n",
    "            preds.append(pred.cpu())\n",
    "            correct_predictions_test += torch.sum(pred == label).item()\n",
    "    if verbose==1:\n",
    "        print(\"Test Accuracy:\", correct_predictions_test/len(test_loader.dataset))    \n",
    "        print(\"True Positive Rate:\", recall_score(torch.cat(labels), torch.cat(preds)))\n",
    "        print(\"True Negative Rate:\", specificity_score(torch.cat(labels), torch.cat(preds)))\n",
    "        print(\"Predictions:\",preds)\n",
    "        print(\"True Labels:\",labels)\n",
    "    else:\n",
    "        return (correct_predictions_test/len(test_loader.dataset), recall_score(torch.cat(labels), torch.cat(preds)),\n",
    "               specificity_score(torch.cat(labels), torch.cat(preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab693a",
   "metadata": {},
   "source": [
    "## 1. Patch Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5939c8",
   "metadata": {},
   "source": [
    "27 models are trained for each patch location for each modality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7990a023",
   "metadata": {},
   "source": [
    "### Training MRI individual patch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0b1f991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set seeds \n",
    "torch.manual_seed(101)\n",
    "torch.cuda.manual_seed(101)\n",
    "torch.cuda.manual_seed_all(101)\n",
    "random.seed(101)\n",
    "np.random.seed(101)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "mri_patch_models = []\n",
    "mri_accuracies = []\n",
    "mri_true_pos_rates = []\n",
    "mri_true_neg_rates = []\n",
    "\n",
    "# For each patch location, train a ResNet model on the image patches in that location\n",
    "for i in range(27):\n",
    "    patch_model = ResNetV2.generate_model(\n",
    "        model_depth=10,\n",
    "        n_classes=1,\n",
    "        n_input_channels=1,\n",
    "        shortcut_type='B',\n",
    "        conv1_t_size=7,\n",
    "        conv1_t_stride=2,\n",
    "        no_max_pool=False,\n",
    "        widen_factor=1.0).to(device)\n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "    patience = 20\n",
    "    no_improvement = 0\n",
    "    \n",
    "    # Binary Cross Entropy Loss\n",
    "    error = nn.BCELoss()\n",
    "\n",
    "    # SGD Optimizer\n",
    "    optimiser = SGD(patch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(optimiser, start_factor=1.0, end_factor=0.1, total_iters=10)\n",
    "    \n",
    "    for epoch in range(1000):\n",
    "        #print(f\"----------------------------EPOCH {epoch} PATCH {i}-------------------------------\")\n",
    "        patch_model.train()\n",
    "        train_model(patch_model, patch_train_dataloaders_MRI[i], optimiser, error, scheduler, True)\n",
    "\n",
    "        patch_model.eval()\n",
    "        val_loss = validate_model(patch_model, patch_val_dataloaders_MRI[i], error, True)\n",
    "        \n",
    "        # Save model weights if improvement seen\n",
    "        # Otherwise stop model training if there is no improvement in loss after \"patience\" number of runs\n",
    "        if val_loss <= best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improvement = 0\n",
    "            torch.save(patch_model.state_dict(), f\"./patch_temp/PATCH_TEMP{i}\")\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            if no_improvement <= patience:\n",
    "                continue\n",
    "            else:\n",
    "                #print(f\"BEST VAL ACC: {best_val_loss}\")\n",
    "                break\n",
    "         \n",
    "    #print(f\"----------------------------TEST RESULTS PATCH{i}-------------------------------\")\n",
    "    patch_model.load_state_dict(torch.load(f\"./patch_temp/PATCH_TEMP{i}\"))\n",
    "    patch_model.eval()\n",
    "    scores = evaluate_model(patch_model, patch_test_dataloaders_MRI[i], error, True,verbose=0)\n",
    "    mri_accuracies.append(scores[0])\n",
    "    mri_true_pos_rates.append(scores[1])\n",
    "    mri_true_neg_rates.append(scores[2])\n",
    "    mri_patch_models.append(patch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "643c2c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test True Positive Rate</th>\n",
       "      <th>Test True Negative Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patch Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.51</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test Accuracy  Test True Positive Rate  Test True Negative Rate\n",
       "Patch Number                                                                 \n",
       "1                      0.59                     0.95                     0.20\n",
       "2                      0.66                     0.76                     0.55\n",
       "3                      0.61                     0.71                     0.50\n",
       "4                      0.66                     0.67                     0.65\n",
       "5                      0.56                     0.76                     0.35\n",
       "6                      0.59                     0.71                     0.45\n",
       "7                      0.59                     0.76                     0.40\n",
       "8                      0.71                     0.81                     0.60\n",
       "9                      0.54                     0.67                     0.40\n",
       "10                     0.63                     0.71                     0.55\n",
       "11                     0.61                     0.81                     0.40\n",
       "12                     0.51                     0.71                     0.30\n",
       "13                     0.71                     0.86                     0.55\n",
       "14                     0.61                     0.76                     0.45\n",
       "15                     0.51                     1.00                     0.00\n",
       "16                     0.66                     0.71                     0.60\n",
       "17                     0.71                     0.86                     0.55\n",
       "18                     0.63                     0.76                     0.50\n",
       "19                     0.66                     0.86                     0.45\n",
       "20                     0.56                     0.90                     0.20\n",
       "21                     0.51                     0.86                     0.15\n",
       "22                     0.68                     0.81                     0.55\n",
       "23                     0.61                     0.76                     0.45\n",
       "24                     0.54                     0.71                     0.35\n",
       "25                     0.68                     0.71                     0.65\n",
       "26                     0.68                     0.76                     0.60\n",
       "27                     0.63                     0.62                     0.65"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_patch_scores = pd.DataFrame(list(zip([i for i in range(1,28)], mri_accuracies, mri_true_pos_rates, mri_true_neg_rates)),\n",
    "              columns=['Patch Number','Test Accuracy','Test True Positive Rate', 'Test True Negative Rate'])\n",
    "mri_patch_scores.set_index('Patch Number').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb803ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload weights (for rerunning)\n",
    "mri_models = []\n",
    "for i in range(27):\n",
    "    patch_model = ResNetV2.generate_model(\n",
    "        model_depth=10,\n",
    "        n_classes=1,\n",
    "        n_input_channels=1,\n",
    "        shortcut_type='B',\n",
    "        conv1_t_size=7,\n",
    "        conv1_t_stride=2,\n",
    "        no_max_pool=False,\n",
    "        widen_factor=1.0).to(device)\n",
    "    patch_model.load_state_dict(torch.load(f\"./patch_temp/PATCH_TEMP{i}\"))\n",
    "    mri_models.append(patch_model)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e9cb7",
   "metadata": {},
   "source": [
    "### Training PET Individual Patch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fd6cc75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "torch.manual_seed(101)\n",
    "torch.cuda.manual_seed(101)\n",
    "random.seed(101)\n",
    "np.random.seed(101)\n",
    "\n",
    "\n",
    "pet_patch_models = []\n",
    "pet_accuracies = []\n",
    "pet_true_pos_rates = []\n",
    "pet_true_neg_rates = []\n",
    "\n",
    "# For each patch location, train a resnet model on the image patches in that location\n",
    "for i in range(27):\n",
    "    patch_model = ResNetV2.generate_model(\n",
    "        model_depth=10,\n",
    "        n_classes=1,\n",
    "        n_input_channels=1,\n",
    "        shortcut_type='B',\n",
    "        conv1_t_size=7,\n",
    "        conv1_t_stride=2,\n",
    "        no_max_pool=False,\n",
    "        widen_factor=1.0).to(device)\n",
    "    \n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "    patience = 20\n",
    "    no_improvement = 0\n",
    "    \n",
    "    # Binary Cross Entropy Loss\n",
    "    error = nn.BCELoss()\n",
    "\n",
    "    # SGD Optimizer\n",
    "    optimiser = SGD(patch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(optimiser, start_factor=1.0, end_factor=0.1, total_iters=10)\n",
    "    \n",
    "    for epoch in range(1000):\n",
    "        #print(f\"----------------------------EPOCH {epoch} PATCH {i}-------------------------------\")\n",
    "        patch_model.train()\n",
    "        train_model(patch_model, patch_train_dataloaders_PET[i], optimiser, error, scheduler, True)\n",
    "\n",
    "        patch_model.eval()\n",
    "        val_loss = validate_model(patch_model, patch_val_dataloaders_PET[i], error, True)\n",
    "        \n",
    "        # Save model weights if improvement seen\n",
    "        # Otherwise stop model training if there is no improvement in loss after \"patience\" number of runs\n",
    "        if val_loss <= best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improvement = 0\n",
    "            torch.save(patch_model.state_dict(), f\"./patch_temp/PET_PATCH_TEMP{i}\")\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            if no_improvement <= patience:\n",
    "                continue\n",
    "            else:\n",
    "                #print(f\"BEST VAL ACC: {best_val_loss}\")\n",
    "                break\n",
    "         \n",
    "    #print(\"----------------------------TEST RESULTS-------------------------------\")\n",
    "    patch_model.load_state_dict(torch.load(f\"./patch_temp/PET_PATCH_TEMP{i}\"))\n",
    "    patch_model.eval()\n",
    "    scores = evaluate_model(patch_model, patch_test_dataloaders_PET[i], error, True,verbose=0)\n",
    "    pet_accuracies.append(scores[0])\n",
    "    pet_true_pos_rates.append(scores[1])\n",
    "    pet_true_neg_rates.append(scores[2])\n",
    "    pet_patch_models.append(patch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04842bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test True Positive Rate</th>\n",
       "      <th>Test True Negative Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patch Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test Accuracy  Test True Positive Rate  Test True Negative Rate\n",
       "Patch Number                                                                 \n",
       "1                      0.73                     0.71                     0.75\n",
       "2                      0.73                     0.67                     0.80\n",
       "3                      0.71                     0.67                     0.75\n",
       "4                      0.63                     0.57                     0.70\n",
       "5                      0.71                     0.67                     0.75\n",
       "6                      0.73                     0.67                     0.80\n",
       "7                      0.71                     0.57                     0.85\n",
       "8                      0.66                     0.57                     0.75\n",
       "9                      0.68                     0.67                     0.70\n",
       "10                     0.68                     0.62                     0.75\n",
       "11                     0.73                     0.71                     0.75\n",
       "12                     0.71                     0.62                     0.80\n",
       "13                     0.68                     0.57                     0.80\n",
       "14                     0.73                     0.76                     0.70\n",
       "15                     0.68                     0.67                     0.70\n",
       "16                     0.73                     0.52                     0.95\n",
       "17                     0.59                     0.48                     0.70\n",
       "18                     0.63                     0.52                     0.75\n",
       "19                     0.61                     0.48                     0.75\n",
       "20                     0.71                     0.67                     0.75\n",
       "21                     0.63                     0.48                     0.80\n",
       "22                     0.63                     0.43                     0.85\n",
       "23                     0.68                     0.62                     0.75\n",
       "24                     0.66                     0.52                     0.80\n",
       "25                     0.66                     0.43                     0.90\n",
       "26                     0.73                     0.67                     0.80\n",
       "27                     0.71                     0.62                     0.80"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_patch_scores = pd.DataFrame(list(zip([i for i in range(1,28)], pet_accuracies, pet_true_pos_rates, pet_true_neg_rates)),\n",
    "              columns=['Patch Number','Test Accuracy','Test True Positive Rate', 'Test True Negative Rate'])\n",
    "pet_patch_scores.set_index('Patch Number').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fbc776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload weights (for rerunning)\n",
    "pet_models = []\n",
    "for i in range(27):\n",
    "    patch_model = ResNetV2.generate_model(\n",
    "        model_depth=10,\n",
    "        n_classes=1,\n",
    "        n_input_channels=1,\n",
    "        shortcut_type='B',\n",
    "        conv1_t_size=7,\n",
    "        conv1_t_stride=2,\n",
    "        no_max_pool=False,\n",
    "        widen_factor=1.0).to(device)\n",
    "    patch_model.load_state_dict(torch.load(f\"./patch_temp/PET_PATCH_TEMP{i}\"))\n",
    "    pet_models.append(patch_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b14b7d",
   "metadata": {},
   "source": [
    "# 2. Patch Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edfdee",
   "metadata": {},
   "source": [
    "The models trained below are at the whole image level. Features from the 27 models trained on each patch location will be concatenated and used for the final global classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dbe47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking all 27 patch based datasets to create a single subject level dataset\n",
    "# We will now have a subject level dataset where each row is a subject and their 27 patch images\n",
    "# e.g row 1 would be: [patch_1,....,patch_27] for subject 1\n",
    "\n",
    "all_patches_train_MRI = torch.stack([dataset.tensors[0] for dataset in patch_train_datasets_MRI], dim=1)\n",
    "all_patches_val_MRI = torch.stack([dataset.tensors[0] for dataset in patch_val_datasets_MRI], dim=1)\n",
    "all_patches_test_MRI = torch.stack([dataset.tensors[0] for dataset in patch_test_datasets_MRI], dim=1)\n",
    "\n",
    "all_patches_train_PET = torch.stack([dataset.tensors[0] for dataset in patch_train_datasets_PET], dim=1)\n",
    "all_patches_val_PET = torch.stack([dataset.tensors[0] for dataset in patch_val_datasets_PET], dim=1)\n",
    "all_patches_test_PET = torch.stack([dataset.tensors[0] for dataset in patch_test_datasets_PET], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b77444f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "all_patches_train_dataloader_MRI = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(all_patches_train_MRI, train_y), \n",
    "                                                                  batch_size = batch_size, shuffle = True)\n",
    "all_patches_val_dataloader_MRI = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(all_patches_val_MRI, val_y), \n",
    "                                                                 batch_size = batch_size, shuffle = False)\n",
    "all_patches_test_dataloader_MRI = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(all_patches_test_MRI, test_y), \n",
    "                                                                  batch_size = batch_size, shuffle = False)\n",
    "\n",
    "all_patches_train_dataloader_PET = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(all_patches_train_PET, train_y), \n",
    "                                                                  batch_size = batch_size, shuffle = True)\n",
    "all_patches_val_dataloader_PET = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(all_patches_val_PET, val_y), \n",
    "                                                                  batch_size = batch_size, shuffle = False)\n",
    "all_patches_test_dataloader_PET = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(all_patches_test_PET, test_y), \n",
    "                                                                  batch_size = batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa0f3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our final multi stream network\n",
    "# This network uses the feature maps of the 27 patch models trained previously above as inputs\n",
    "class patch_fusion_CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    This network uses the feature maps of the 27 patch models trained previously above as inputs.\n",
    "    Feature maps are concatenated and passed through a dense layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, patch_models):\n",
    "        super().__init__()\n",
    "        self.patch_models = nn.ModuleList(patch_models)\n",
    "        self.drop= nn.Dropout(p=0.4)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2700, 1000) \n",
    "        self.rel1 = nn.ReLU()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(1000)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1000, 200) \n",
    "        self.rel2 = nn.ReLU()\n",
    "        self.batch_norm2 = nn.BatchNorm1d(200)\n",
    "        \n",
    "        self.fc3 = nn.Linear(2700, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        patch_outputs = []\n",
    "        for i in range(27):\n",
    "            patch_output, _ = self.patch_models[i](x[:, i])  \n",
    "            patch_outputs.append(self.drop(patch_output))\n",
    "        x = torch.cat(patch_outputs, dim=1)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28d0c3",
   "metadata": {},
   "source": [
    "### MRI ensemble patch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf33f24c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST VAL LOSS: 0.04719100056624994\n",
      "----------------------------TEST RESULTS-------------------------------\n",
      "Test Accuracy: 0.6829268292682927\n",
      "True Positive Rate: 0.8095238095238095\n",
      "True Negative Rate: 0.55\n"
     ]
    }
   ],
   "source": [
    "MRI_patch_fusion_model = patch_fusion_CNN(mri_models).to(device)\n",
    "\n",
    "#Freeze layers of the 27 individual patch models\n",
    "for patch_model in MRI_patch_fusion_model.patch_models:\n",
    "    for name, param in patch_model.named_parameters():      \n",
    "            param.requires_grad = False \n",
    "\n",
    "# CNN model training\n",
    "torch.manual_seed(101)\n",
    "torch.cuda.manual_seed(101)\n",
    "random.seed(101)\n",
    "np.random.seed(101)\n",
    "\n",
    "# Binary Cross Entropy Loss\n",
    "error = nn.BCELoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "optimiser = SGD(MRI_patch_fusion_model.parameters(), lr=0.0001, momentum=0.9)\n",
    "scheduler = lr_scheduler.LinearLR(optimiser, start_factor=1.0, end_factor=0.1, total_iters=10)\n",
    "\n",
    "# Validation Hyperparameters for early stopping\n",
    "best_val_loss = np.inf\n",
    "patience = 20\n",
    "no_improvement = 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    #print(f\"----------------------------EPOCH {epoch}-------------------------------\")\n",
    "    MRI_patch_fusion_model.train()\n",
    "    train_model(MRI_patch_fusion_model, all_patches_train_dataloader_MRI, optimiser, error, scheduler)\n",
    "    \n",
    "    MRI_patch_fusion_model.eval()\n",
    "    avg_val_loss = validate_model(MRI_patch_fusion_model, all_patches_val_dataloader_MRI, error)\n",
    "    \n",
    "    # Save model weights if improvement seen\n",
    "    # Otherwise stop model training if there is no improvement in loss after \"patience\" number of runs\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        no_improvement = 0\n",
    "        torch.save(MRI_patch_model.state_dict(), \"./trained_models_2/MRI_PATCH_MODEL\")\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "        if no_improvement <= patience:\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"BEST VAL LOSS: {best_val_loss}\")\n",
    "            break\n",
    "            \n",
    "print(\"----------------------------TEST RESULTS-------------------------------\")\n",
    "MRI_patch_fusion_model.load_state_dict(torch.load(\"./trained_models_2/MRI_PATCH_MODEL\"))\n",
    "MRI_patch_fusion_model.eval()\n",
    "evaluate_model(MRI_patch_fusion_model, all_patches_test_dataloader_MRI, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84d9de0",
   "metadata": {},
   "source": [
    "### PET ensemble patch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e548130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST VAL LOSS: 0.0446309679892005\n",
      "----------------------------TEST RESULTS-------------------------------\n",
      "Test Accuracy: 0.7560975609756098\n",
      "True Positive Rate: 0.6666666666666666\n",
      "True Negative Rate: 0.85\n",
      "Predictions: [tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.]), tensor([0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.]), tensor([0., 0., 0., 1., 1., 1., 1., 1., 0.])]\n",
      "True Labels: [tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.]), tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.]), tensor([0., 0., 0., 1., 1., 1., 1., 1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "PET_patch_fusion_model = patch_fusion_CNN(pet_models).to(device)\n",
    "\n",
    "#Freeze layers of individual patch models\n",
    "for patch_model in PET_patch_fusion_model.patch_models:\n",
    "    for name, param in patch_model.named_parameters():\n",
    "        param.requires_grad = False \n",
    "\n",
    "# CNN model training\n",
    "torch.manual_seed(101)\n",
    "torch.cuda.manual_seed(101)\n",
    "random.seed(101)\n",
    "np.random.seed(101)\n",
    "\n",
    "# Binary Cross Entropy Loss\n",
    "error = nn.BCELoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "optimiser = SGD(PET_patch_fusion_model.parameters(), lr=0.0001, momentum=0.9)\n",
    "scheduler = lr_scheduler.LinearLR(optimiser, start_factor=1.0, end_factor=0.1, total_iters=10)\n",
    "\n",
    "# Validation Hyperparameters for early stopping\n",
    "best_val_loss = np.inf\n",
    "patience = 20\n",
    "no_improvement = 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    #print(f\"----------------------------EPOCH {epoch}-------------------------------\")\n",
    "    PET_patch_fusion_model.train()\n",
    "    train_model(PET_patch_fusion_model, all_patches_train_dataloader_PET, optimiser, error, scheduler)\n",
    "    \n",
    "    PET_patch_fusion_model.eval()\n",
    "    avg_val_loss = validate_model(PET_patch_fusion_model, all_patches_val_dataloader_PET, error)\n",
    "    \n",
    "    # Save model weights if improvement seen\n",
    "    # Otherwise stop model training if there is no improvement in loss after \"patience\" number of runs\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        no_improvement = 0\n",
    "        torch.save(PET_patch_model.state_dict(), \"./trained_models_2/1PET_PATCH_MODEL\")\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "        if no_improvement <= patience:\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"BEST VAL LOSS: {best_val_loss}\")\n",
    "            break\n",
    "            \n",
    "print(\"----------------------------TEST RESULTS-------------------------------\")\n",
    "PET_patch_fusion_model.load_state_dict(torch.load(\"./trained_models_2/1PET_PATCH_MODEL\"))\n",
    "PET_patch_fusion_model.eval()\n",
    "evaluate_model(PET_patch_fusion_model, all_patches_test_dataloader_PET, error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
